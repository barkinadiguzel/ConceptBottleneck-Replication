# ğŸŒ® ConceptBottleneck-Replication â€“ Interpretable Neural Reasoning via Concepts

This repository provides a **PyTorch-based replication** of  
**Concept Bottleneck Models â€“ Koh et al., ICML 2020**.

The focus is **translating the theoretical concept bottleneck framework into a clean, modular, and practical architecture**,  
rather than chasing benchmark SOTA results.

- Learns **human-interpretable concepts** as an intermediate representation ğŸ§©  
- Enables **direct concept intervention and counterfactual reasoning** ğŸ§ª  
- Modular & lightweight, **plug-and-play for any encoder backbone** ğŸ› ï¸  

**Paper reference:** [Concept Bottleneck Models â€“ Koh et al., 2020](https://arxiv.org/abs/2007.04612) ğŸ“„

---

## ğŸ§  Overview â€“ Concept Bottleneck Pipeline

![CBM Overview](images/figmix.jpg)

The core idea:

> Force the model to reason through **human-specified concepts** before making a final prediction.

Instead of learning a black-box mapping  
$x \rightarrow y$,  
the model is structured as:

$$
x \;\longrightarrow\; c \;\longrightarrow\; y
$$

Where:
- $x$ = raw input (image, signal, etc.)
- $c$ = vector of interpretable concepts (bone spur, wing color, beak shape, â€¦)
- $y$ = final prediction (disease grade, bird species, â€¦)

This creates a **bottleneck**: the model is forced to explain itself in terms of concepts.

---


## ğŸ§® CBM Computation â€“ Math Essentials

### Concept Prediction (x â†’ c)

Given input $x$ and encoder $E$:

$$
h = E(x), \quad \hat{c} = g(h)
$$

Where:
- $h \in \mathbb{R}^d$ is feature representation  
- $\hat{c} \in \mathbb{R}^k$ is predicted concept vector  

Each dimension corresponds to one human-defined concept.


### Decision Layer (c â†’ y)

Final prediction is made **only using concepts**:

$$
\hat{y} = f(\hat{c})
$$

This guarantees that:
> The model cannot bypass the concepts.

All reasoning must pass through the bottleneck.


### Joint Bottleneck Loss

Training objective:

$$
\mathcal{L} = \mathcal{L}_Y(f(g(x)), y) + \lambda \sum_{j=1}^k \mathcal{L}_{C_j}(g_j(x), c_j)
$$

Special cases:
- $\lambda \to 0$ â†’ standard black-box model  
- $\lambda \to \infty$ â†’ strict concept supervision  

---

## ğŸ§ª Concept Intervention â€“ Model Surgery

One of the defining features of CBMs is **intervention**.

At test time, we can:
1. Predict concepts
$$\hat{c} = g(x)$$  
3. Manually edit a concept:
$$\hat{c}_j \leftarrow c_j^\text{new}$$
4. Recompute prediction:
$$\hat{y}_\text{new} = f(\hat{c})$$

This enables:

- Counterfactual reasoning  
- Human-in-the-loop correction  
- Debugging concept failures  
- Interpretability via causal probing  

Example:
> â€œIf the model did not think there was a bone spur, would it still predict severe arthritis?â€

CBMs can answer this directly.

---

## ğŸ§  What the Model Enables

- Explicit reasoning via **human concepts**
- Direct **model introspection**
- Concept-level debugging
- Counterfactual explanations
- Robustness via semantic supervision
- Human-model collaboration

The model is **interpretable by construction**.

---

## ğŸ“¦ Repository Structure

```bash
ConceptBottleneck-Replication/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ backbone/
â”‚   â”‚   â””â”€â”€ encoder.py          # Feature extractor (CNN / MLP)
â”‚   â”‚
â”‚   â”œâ”€â”€ concepts/
â”‚   â”‚   â””â”€â”€ concept_head.py     # g(x): feature â†’ concept vector
â”‚   â”‚
â”‚   â”œâ”€â”€ decision/
â”‚   â”‚   â””â”€â”€ classifier.py      # f(c): concept â†’ output
â”‚   â”‚
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â””â”€â”€ cbm.py             # Full x â†’ c â†’ y model
â”‚   â”‚
â”‚   â”œâ”€â”€ loss/
â”‚   â”‚   â””â”€â”€ cbm_loss.py        # Joint bottleneck loss
â”‚   â”‚
â”‚   â”œâ”€â”€ intervention/
â”‚   â”‚   â””â”€â”€ intervene.py      # Concept editing & forward
â”‚   â”‚
â”‚   â””â”€â”€ config.py             # concept_dim, lambda, hidden_dim, etc.
â”‚
â”œâ”€â”€ images/
â”‚   â””â”€â”€ figmix.jpg             # CBM overview figure
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
---


## ğŸ”— Feedback

For questions or feedback, contact: [barkin.adiguzel@gmail.com](mailto:barkin.adiguzel@gmail.com)
